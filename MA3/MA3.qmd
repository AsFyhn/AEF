---
title: "Mandatory Assignment 2"
author: "Asbjørn Fyhn & Emil Beckett Kolko"
date: "2024-05-10"
execute: 
  echo: false
  warning: false
  output: false
jupyter: python3
format:
  pdf: 
    number-sections: true
    colorlinks: true
    geometry:
      - top=20mm
      - left=20mm
      - bottom=20mm
      - right=20mm
    cite-method: natbib
    fontsize: 12pt
---
**Introduction**

**Exercise 1**
```{python}
import pandas as pd
import numpy as np
import sqlite3

from plotnine import *
from mizani.formatters import percent_format
from itertools import product
from scipy.stats import expon
from scipy.optimize import minimize


#Connecting to the database
tidy_finance = sqlite3.connect(
    database=f"/Users/emilkolko/Downloads/tidy_finance_python.sqlite"
)

#Reading in crsp_monthly dataset
crsp_monthly = (pd.read_sql_query(
    sql="SELECT permno, month, ret_excess FROM crsp_monthly",
    con=tidy_finance,
    parse_dates={"month"})
)

#Dropping all stocks before 1962
crsp_monthly = crsp_monthly.query("month >= '1962-01-01'")

#Dropping all stocks after 2020
crsp_monthly = crsp_monthly.query("month < '2021-01-01'")

#Dropping all stocks with missing values
crsp_monthly = crsp_monthly.groupby("permno").filter(lambda x: x.shape[0] == 708)

#Summarizing the table with mean return
summary_stats = crsp_monthly.groupby('permno').agg(
    mean_return=('ret_excess', 'mean'),      # Mean of 'return' per 'permno'
)

# Calculate the average of excess return across all stocks
average_mean_return = summary_stats['mean_return'].mean()
```
The CRSP Monthly dataset contains both observations before 1962 and after 2020. We remove those observations such that the dataset only contains data from 1962-2020. Thereafter, we only keep stocks that have exactly 708 observations of excess return. This ensures that there are no stocks with interrupted observations in our dataset, as there is exactly 708 months between January 1962 and December 2020. Our investment universe now consists of `{python} crsp_monthly.groupby("permno").size().shape[0]` different stocks with an average monthly excess return of `{python} round(average_mean_return*100, 2)`%

**Exercise 2**
The portfolio choice problem for a transactions-cost adjusted certainty equivalent maximization with risk aversion parameter $\gamma$ is given by

$\omega_{t+1}^* := \arg \: \max \: \left( \hat{\omega}^\prime \mu - \nu_t(\omega, \omega_{t^+}, \beta) - \frac{\gamma}{2} \omega^\prime \hat{\Sigma} \omega \right)$

Where ${\omega \in \mathbb{R}^N, \, \iota^\prime \omega = 1}$

In the mandatory assignment the proposed transaction costs are specified as 

$TC(\omega,\omega_{t^+})=\lambda(\omega-\omega_{t^+})^\prime\Sigma(\omega-\omega_{t^+})$ 

To follow the proofs presented in Hautsch & Voigt (2019) we define $\lambda\equiv\frac{\beta}{2}$ where $\beta>0$ is just a cost parameter like $\lambda$.

The optimal portfolio thus takes the form

$\omega_{t+1}^* := \arg \: \max \: \left( \hat{\omega}^\prime \mu - \frac{\beta}{2}(\omega-\omega_{t^+})^\prime\Sigma(\omega-\omega_{t^+}) - \frac{\gamma}{2} \omega^\prime \hat{\Sigma} \omega \right)=\arg \: \max \: \omega^\prime\mu^*-\frac{\gamma}{2}\omega^\prime\Sigma^*\omega$

Where

$\Sigma^*=\left(1+\frac{\beta}{\gamma}\right)\Sigma$

And

$\mu^*=\mu+\beta\Sigma\omega_{t^+}$

With these new return parameters, we can derive a closed-form solution for the mean-variance efficient portfolio. We compute the mean-variance efficient portfolio by solving for $\gamma$:

$\omega_{t+1}^* = \frac{1}{\gamma} \left( \Sigma^{*-1} - \frac{1}{\iota^\prime \Sigma^{*-1}\iota} \Sigma^{*-1} \iota\iota^\prime\Sigma^{*-1}\right) \mu^* + \frac{1}{\iota^\prime \Sigma^{*-1}\iota} \Sigma^{*-1}\iota$

$=\frac{1}{\gamma+\beta} \left( \Sigma^{-1}-\frac{1}{\iota^\prime \Sigma^{-1}\iota} \Sigma^{-1} \iota\iota^\prime\Sigma^{-1}\right)(\mu+\beta\Sigma\omega_{t^+}) + \omega^{mvp}$

$=\omega_{t+1}+\frac{\beta}{\gamma+\beta}(\omega_{t^+}-\omega^{mvp})$

Where $\omega_{t+1}$ is the efficient portfolio without transaction costs and risk aversion parameter $\gamma+\beta$.

$\omega^{mvp}=\frac{1}{\iota^\prime \Sigma^{-1}\iota} \Sigma^{-1}\iota$ is the minimum variance allocation.

We see that the optimal weights are a linear combination of the efficient portfolio without transaction costs and the difference between the weights of the minimum variance portfolio and the portfolio before reallocation. The weight $\frac{\beta}{\beta+\gamma}$ only depends on the risk aversion and the cost parameter. Thus, the weight $\frac{\beta}{\beta+\gamma}$ is not affected by $\Sigma$. Only $\omega_{t+1}$ and $\omega^{mvp}$ is affected by $\Sigma$. Therefore, the effect of making transaction costs proportional to volatility is ambigous and depends on how $\beta$ and $\Sigma$ affect each other.

A simpler case discussed in the lectures is when we model exogenous quadratic transactions costs. Here the effect of higher volatility has a clear effect. Periods with high volatility shifts the optimal portfolio allocation towards the global minimum-variance portfolio. This makes sense as the risk needs to be reduced in high volatility periods.

From a supply/demand point of view however, endogonous transaction costs linked to volatility makes sense. In a high volatile environment, investors reallocate their portfolio more frequently to maintain optimal portfolio weights. Economic theory suggests that a higher demand must yield a higher price. Therefore, linking transaction costs to volatility makes sense.

We now write a function that computes the optimal weight for different values of the transaction cost parameter $\lambda\equiv\frac{\beta}{2}$ and present the results in the graph below:
```{python}
# Pivot the data to have stocks as columns and months as rows
returns_pivot = crsp_monthly.pivot(index='month', columns='permno', values='ret_excess')

# Calculate the expected returns (mean excess returns per stock) as a vector
mu = returns_pivot.mean(axis=0).values

# Calculate the covariance matrix of excess returns
sigma = returns_pivot.cov().values

# Calculate the minimum variance portfolio
# First we create a vector of ones with the same length as the number of stocks
n_industries = crsp_monthly.groupby("permno").size().shape[0]
print(n_industries)
# Next we calculate the inverse of the covariance matrix and multiply it with the vector of ones
w_mvp = np.linalg.inv(sigma) @ np.ones(n_industries)
# Finally we normalize the weights so they sum to one
w_mvp = w_mvp/w_mvp.sum()

# Writing a function that computes the optimal weights. The structure is inspired by the "Constrained optimization and backtesting" exercise
def compute_efficient_weight(sigma, 
                             mu, 
                             gamma=4, 
                             beta=0,
                             w_prev=np.ones(sigma.shape[1])/sigma.shape[1]):
    """Compute efficient portfolio weights."""
    
    n = sigma.shape[1]
    iota = np.ones(n)
    # sigma_processed = sigma+(beta/gamma)*np.eye(n) 
    # mu_processed = mu+beta*w_prev

    sigma_processed = sigma+beta/gamma*sigma # Chanced to fit transaction costs proportional to volatility
    mu_processed = mu+beta*sigma*w_prev # Ditto

    sigma_inverse = np.linalg.inv(sigma_processed)

    w_mvp = sigma_inverse @ iota
    w_mvp = w_mvp/np.sum(w_mvp)
    w_opt = w_mvp+((1/gamma)*\
        (sigma_inverse-np.outer(w_mvp, iota) @ sigma_inverse) @ mu_processed)

# Mu_processed ændrer opbygning efter jeg transformerer den. Måske kan Asbjørn hjælpe med det?    
 #Af ovenstående grund (tror jerg) er (1/gamma)*\(sigma_inverse-np.outer(w_mvp, iota) @ sigma_inverse) @ mu_processed enormt småt, så w_opt og w_mvp bliver essentielt det samme. Derfor bliver linjen lineær (når vi ændrer mu og sigma processed)

    return w_opt

w_efficient = compute_efficient_weight(sigma, mu)
```

```{python}
# | output : true
# Calculating the function from before but for different values of beta
gammas = [4]
betas = 20*expon.ppf(np.arange(1, 100)/100, scale=1)

transaction_costs = (pd.DataFrame(
    list(product(gammas, betas)), 
    columns=["gamma", "beta"]
  )
  .assign(
    weights=lambda x: x.apply(lambda y:
      compute_efficient_weight(
        sigma, mu, gamma=y["gamma"], beta=y["beta"]/10000, w_prev=w_mvp), 
      axis=1
    ),
    concentration=lambda x: x["weights"].apply(
      lambda x: np.sum(np.abs(x-w_mvp))
    )
  )
)

# Plotting the results
rebalancing_plot = (
    ggplot(transaction_costs, 
           aes(x="beta", y="concentration",
               color="factor(gamma)", linetype="factor(gamma)")) +
    geom_line() +
    guides(linetype=None) +
    labs(x="Transaction cost parameter", y="Distance from MVP",
         color="Risk aversion",
         title=("Portfolio weights for different risk aversion and "
                "transaction cost"))
)
rebalancing_plot.draw()
```