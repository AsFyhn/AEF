---
title: "Mandatory Assignment 2"
author: "AsbjÃ¸rn Fyhn & Emil Beckett Kolko"
date: "2024-05-10"
execute: 
  echo: false
  warning: false
  output: false
jupyter: python3
format:
  pdf: 
    number-sections: true
    colorlinks: true
    geometry:
      - top=20mm
      - left=20mm
      - bottom=20mm
      - right=20mm
    cite-method: natbib
    fontsize: 12pt
---
**Introduction**

**Exercise 1**
```{python}
import pandas as pd
import numpy as np
import sqlite3

from plotnine import *
from mizani.formatters import percent_format
from itertools import product
from scipy.stats import expon
from scipy.optimize import minimize


#Connecting to the database
tidy_finance = sqlite3.connect(
    database=f"/Users/emilkolko/Downloads/tidy_finance_python.sqlite"
)

#Reading in crsp_monthly dataset
crsp_monthly = (pd.read_sql_query(
    sql="SELECT permno, month, ret_excess FROM crsp_monthly",
    con=tidy_finance,
    parse_dates={"month"})
)

#Dropping all stocks before 1962
crsp_monthly = crsp_monthly.query("month >= '1962-01-01'")

#Dropping all stocks after 2020
crsp_monthly = crsp_monthly.query("month < '2021-01-01'")

#Dropping all stocks with missing values
crsp_monthly = crsp_monthly.groupby("permno").filter(lambda x: x.shape[0] == 708)

#Summarizing the table with mean return
summary_stats = crsp_monthly.groupby('permno').agg(
    mean_return=('ret_excess', 'mean'),      # Mean of 'return' per 'permno'
)

# Calculate the average of excess return across all stocks
average_mean_return = summary_stats['mean_return'].mean()
```
The CRSP Monthly dataset contains both observations before 1962 and after 2020. We remove those observations such that the dataset only contains data from 1962-2020. Thereafter, we only keep stocks that have exactly 708 observations of excess return. This ensures that there are no stocks with interrupted observations in our dataset, as there is exactly 708 months between January 1962 and December 2020. Our investment universe now consists of `{python} crsp_monthly.groupby("permno").size().shape[0]` different stocks with an average monthly excess return of `{python} round(average_mean_return*100, 2)`%

**Exercise 2**

**Bullet 1**
The portfolio choice problem for a transactions-cost adjusted certainty equivalent maximization with risk aversion parameter $\gamma$ is given by

$\omega_{t+1}^* := \arg \: \max \: \left( \hat{\omega}^\prime \mu - \nu_t(\omega, \omega_{t^+}, \beta) - \frac{\gamma}{2} \omega^\prime \hat{\Sigma} \omega \right)$

Where ${\omega \in \mathbb{R}^N, \, \iota^\prime \omega = 1}$

In the mandatory assignment the proposed transaction costs are specified as 

$TC(\omega,\omega_{t^+})=\lambda(\omega-\omega_{t^+})^\prime\Sigma(\omega-\omega_{t^+})$ 

To follow the proofs presented in Hautsch & Voigt (2019) we define $\lambda\equiv\frac{\beta}{2}$ where $\beta>0$ is just a cost parameter like $\lambda$.

The optimal portfolio thus takes the form

$\omega_{t+1}^* := \arg \: \max \: \left( \hat{\omega}^\prime \mu - \frac{\beta}{2}(\omega-\omega_{t^+})^\prime\Sigma(\omega-\omega_{t^+}) - \frac{\gamma}{2} \omega^\prime \hat{\Sigma} \omega \right)=\arg \: \max \: \omega^\prime\mu^*-\frac{\gamma}{2}\omega^\prime\Sigma^*\omega$

Where

$\Sigma^*=\left(1+\frac{\beta}{\gamma}\right)\Sigma$

And

$\mu^*=\mu+\beta\Sigma\omega_{t^+}$

With these new return parameters, we can derive a closed-form solution for the mean-variance efficient portfolio. We compute the mean-variance efficient portfolio by solving for $\gamma$:

$\omega_{t+1}^* = \frac{1}{\gamma} \left( \Sigma^{*-1} - \frac{1}{\iota^\prime \Sigma^{*-1}\iota} \Sigma^{*-1} \iota\iota^\prime\Sigma^{*-1}\right) \mu^* + \frac{1}{\iota^\prime \Sigma^{*-1}\iota} \Sigma^{*-1}\iota$

$=\frac{1}{\gamma+\beta} \left( \Sigma^{-1}-\frac{1}{\iota^\prime \Sigma^{-1}\iota} \Sigma^{-1} \iota\iota^\prime\Sigma^{-1}\right)(\mu+\beta\Sigma\omega_{t^+}) + \omega^{mvp}$

$=\omega_{t+1}+\frac{\beta}{\gamma+\beta}(\omega_{t^+}-\omega^{mvp})$

Where $\omega_{t+1}$ is the efficient portfolio without transaction costs and risk aversion parameter $\gamma+\beta$.

$\omega^{mvp}=\frac{1}{\iota^\prime \Sigma^{-1}\iota} \Sigma^{-1}\iota$ is the minimum variance allocation.

We see that the optimal weights are a linear combination of the efficient portfolio without transaction costs and the difference between the weights of the minimum variance portfolio and the portfolio before reallocation. The weight $\frac{\beta}{\beta+\gamma}$ only depends on the risk aversion and the cost parameter. Thus, the weight $\frac{\beta}{\beta+\gamma}$ is not affected by $\Sigma$. Only $\omega_{t+1}$ and $\omega^{mvp}$ is affected by $\Sigma$. Therefore, the effect of making transaction costs proportional to volatility is ambiguous and depends on how $\beta$ and $\Sigma$ affect each other.

A simpler case discussed in the lectures is when we model exogenous quadratic transactions costs. Here the effect of higher volatility has a clear effect. Periods with high volatility shifts the optimal portfolio allocation towards the global minimum-variance portfolio. Thus, assuming quadratic transaction costs not related to volatility, provides a result that intuitively makes sense. However, this type of transaction costs are not very realistic (Hautsch & Voigt 2019)

From a supply/demand point of view, endogenous transaction costs linked to volatility makes sense. In a high volatile environment, investors reallocate their portfolio more frequently to maintain optimal portfolio weights. Economic theory suggests that a higher demand must yield a higher price. Therefore, linking transaction costs to volatility makes sense.

**Bullet 2**
We now write a function that computes the optimal weight for different values of the transaction cost parameter $\beta\equiv\lambda*2$. This is done by computing the optimal portfolio weights for rising betas, when we keep the initial allocation (minimum variance portfolio) constant. The optimal portfolio weights are presented relative to the minimum variance portfolio in the graph below. The "distance from MVP" is measured by the sum of absolute deviations from the MVP to the efficient portfolio.
```{python}
# Pivot the data to have stocks as columns and months as rows
returns_pivot = crsp_monthly.pivot(index='month', columns='permno', values='ret_excess')

# Calculate the expected returns (mean excess returns per stock) as a vector
mu = returns_pivot.mean(axis=0).values

# Calculate the covariance matrix of excess returns
sigma = returns_pivot.cov().values

# Calculate the minimum variance portfolio
# First we create a vector of ones with the same length as the number of stocks
n_industries = crsp_monthly.groupby("permno").size().shape[0]
print(n_industries)
# Next we calculate the inverse of the covariance matrix and multiply it with the vector of ones
w_mvp = np.linalg.inv(sigma) @ np.ones(n_industries)
# Finally we normalize the weights so they sum to one
w_mvp = w_mvp/w_mvp.sum()
```
```{python}
# Writing a function that computes the optimal weights. The structure is inspired by the "Constrained optimization and backtesting" exercise but we have chanced key elements. The most important chance is the calculation of sigma_processed and mu_processed.
def compute_efficient_weight(sigma, 
                             mu, 
                             gamma=4, 
                             beta=0,
                             w_prev=np.ones(sigma.shape[1])/sigma.shape[1]):
    """Compute efficient portfolio weights."""
    #Creating a vector of beta=0, so it can be multiplied correctly in sigma_processed and mu_processed
    betas = np.repeat(beta,sigma.shape[0])
    n = sigma.shape[1]
    iota = np.ones(n)
    sigma_processed = sigma+(betas/gamma)*sigma # Chanced to fit transaction costs proportional to volatility
    mu_processed = mu+betas@sigma@w_prev # Ditto

    sigma_inverse = np.linalg.inv(sigma_processed)
    #Specifying portfolio weights for the efficient portfolio
    w_mvp = sigma_inverse @ iota
    w_mvp = w_mvp/np.sum(w_mvp)
    w_opt = w_mvp+((1/gamma)*\
        (sigma_inverse-np.outer(w_mvp, iota) @ sigma_inverse) @ mu_processed)

    return w_opt

w_efficient = compute_efficient_weight(sigma, mu)
```

```{python}
# | output : true
# Computing the optimal weights for different values of beta but with the same inital allocation accounting for sigma's influence on the transaction costs.
gammas = [4]
betas = 20*expon.ppf(np.arange(1, 100)/100, scale=1)

transaction_costs = (pd.DataFrame(
    list(product(gammas, betas)), 
    columns=["gamma", "beta"]
  )
  .assign(
    weights=lambda x: x.apply(lambda y:
      compute_efficient_weight(
        sigma, mu, gamma=y["gamma"], beta=y["beta"]/10, w_prev=w_mvp), 
      axis=1
    ),
    concentration=lambda x: x["weights"].apply(
      lambda x: np.sum(np.abs(x-w_mvp))
    )
  )
)

# Plotting the results
rebalancing_plot = (
    ggplot(transaction_costs, 
           aes(x="beta", y="concentration",
               color="factor(gamma)", linetype="factor(gamma)")) +
    geom_line() +
    guides(linetype=None) +
    labs(x="Beta", y="Distance from MVP",
         color="Risk aversion",
         title=("Portfolio weights for different betas"))
)
rebalancing_plot.draw()
```

We see that a rising $\beta$ makes the investor deviate less and less from his initial allocation (in this instance, the minimum variance portfolio). This makes sense, as it is more expensive to reallocate his portfolio weights. When beta is 0, transaction costs are also zero. In this case, the investor chooses a portfolio on the efficient frontier that matches his risk preference $\gamma=4$. However, when $\beta>0$ he chooses a portfolio between his initial allocation and the portfolio on the efficient frontier.