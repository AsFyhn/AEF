---
title: "Mandatory Assignment 1"
author: "Asbjørn Fyhn & Emil Beckett Kolko"
date: "2024-03-08"
execute: 
  echo: false
  warning: false
  output: false
jupyter: python3
format:
  pdf:
    documentclass: article
    number-sections: true
    colorlinks: true
    geometry:
      - top=20mm
      - left=20mm
      - bottom=20mm
      - right=20mm
    cite-method: natbib
    fontsize: 12pt
---
In the following we complete the exercises for mandatory assignment 1.


<!-- Exercise 1 -->
```{python}

import pandas as pd 
import numpy as np
import yfinance as yf
from datetime import datetime as dt
from plotnine import *
from mizani.formatters import percent_format

# define list of tickers
tickerlist = ['UNH', 'MSFT', 'GS', 'HD', 'CAT', 'CRM', 'MCD',
               'V', 'AMGN', 'TRV', 'AXP', 'BA', 'HON', 'JPM',
                 'IBM', 'AAPL', 'AMZN', 'JNJ', 'PG', 'CVX',
                   'MRK', 'DIS', 'NKE', 'MMM', 'KO', 'WMT', 
                   'DOW', 'CSCO', 'INTC', 'VZ']
return_col = 'log_return' # alternatively use 'ret' to get standard returns
print(Asfyhn er en champ)
```

```{python}
inputdf = yf.download(tickers=tickerlist,period='25y') 
# inputdf = pd.read_pickle(r'DJ_comp.pkl')
# transform the dataset
df = (inputdf
      .get('Adj Close')
      .stack()
      .reset_index()
      .rename(columns={'Date':'date','level_1':'ticker',0:'adj_close'})
      .set_index('date')
      .groupby('ticker')['adj_close']
      .resample('m')
      .last()
      .reset_index()
      .assign(date=lambda x: x['date'].dt.strftime('%Y-%m-%d'))  # Convert date to string
      .query("date >= '2000-01-01'")  # Filter for dates >= 1999-04-01
      .query("date <= '2023-12-31'")  # Filter for dates >= 1999-04-01
      )

# remove all tickers where there is no data for each month 
df = (df
  .groupby(["ticker"])
  .apply(lambda x: x.assign(counts=x["adj_close"].dropna().count()))
  .reset_index(drop=True)
  .query("counts == counts.max()")
  .drop(columns='counts')
  .assign(ret=lambda x: x["adj_close"].pct_change())
  .assign(log_return = lambda x: np.log(x['adj_close']/x['adj_close'].shift(1)) )
)

# check that we have 27 tickers
no_of_tickers = int(df['ticker'].unique().size)
#print(f'The number of tickers in the dataset: { no_of_tickers}')

#
mu = np.array(df.groupby('ticker')[return_col].mean()).T
sigma = np.array(df.pivot(index='date',columns='ticker',values=return_col).cov())

# Calculate Sharpe ratio for each stock
sharpe_ratio = (mu - 0) / np.diag(sigma)
# Print the Sharpe ratio
sr_high = df.groupby('ticker')['ticker'].first().iloc[sharpe_ratio.argmax()]
```

**Exercise 1 and 2**  <!-- The code for this exercise is found above -->  
Based on the monthly return series calculated earlier, we create a vector of the average monthly returns $\mu$ for each series and a variance-covariance matrix $\Sigma$. To calculate the Sharpe-ratio, we use the formula: $Sharpe=\frac{return-r_f}{standarddeviation}$. The stock with the highest Sharpe ratio is `{python} sr_high` with a ration of `{python} sharpe_ratio.max().round(2)`.

```{python}
def calc_return_std(weights, mu, sigma_matrix, factor):
  """
  Calculate the expected return and standard deviation of a portfolio.

  Parameters:
  weights (numpy.ndarray): The weights of the assets in the portfolio.
  mu (numpy.ndarray): The expected returns of the assets.
  sigma_matrix (numpy.ndarray): The covariance matrix of the assets.
  factor (float): A scaling factor.

  Returns:
  tuple: A tuple containing the expected return and standard deviation of the portfolio.
  """
  return_vec = mu.T @ weights * factor 
  vol = np.sqrt(weights.T @ sigma_matrix @ weights) * np.sqrt(factor)
  return return_vec, vol
```

**Exercise 3**  
First of we create a function compute_efficient_frontier which return an object with the inputs that consists of a vector of the estimated expected return, the estimated variance-covariance matrix and a factor that is used to annualise the return, minimum variance portfolio, efficient portfolio that delivers two times the expected return of the minimum variance portfolio and lastly the efficient frontier. We have calculated the inputs as follows:

* The sample average return vector: $\hat{\mu}=\frac{1}{T}\Sigma^T_{t=1}r_t$
* The variance co-variance matrix: $\hat{\Sigma}=\frac{1}{T-1}\Sigma^T_{t=1}(r_t-\hat{\mu})(r_t-\hat{\mu})'$
* The factor is just 12, because we are annualizing monthly data
* We define the minimum variance portfolio as follows: $\omega_{mvp}=\text{arg\:min}\:\omega'\Sigma\omega\:\:s.t.\:\Sigma^N_{i=1}\omega_i=1$,  
where the solution is $\omega_{mvp}=\frac{\Sigma^{-1}\iota}{\iota'\Sigma^{-1}\iota}$  
* And the efficient portfolio as follows: $\omega_{eff}(\bar{\mu})=\text{arg\:min}\:\omega'\Sigma\omega\:\:s.t.\:\omega'\iota=1\:\text{and}\:\omega'\mu\geq\bar{\mu}$,  
where the solution is $\omega_{eff}(\bar{\mu})=\omega_{mvp}+\frac{\tilde{\lambda}}{2}\left(\Sigma^{-1}\mu-\frac{D}{C}\Sigma^{-1}\iota\right)$,  
where $C\equiv\iota'\Sigma^{-1}\iota,\:D\equiv\iota'\Sigma^{-1}\mu,\:E\equiv\mu'\Sigma^{-1}\mu,\:\:\text{and}\:\tilde{\lambda}=2\frac{\bar{\mu}-D/C}{E-D^2/C}$  
* Lastly, in accordence with the mutual fund theorem, we compute the efficient frontier with a linear combination of the risk free rate (0 in this case) and the efficient market portfolio

```{python}
def compute_efficient_frontier(mu_est: np.array, sigma_est: np.array, yearly_factor: int=1) -> pd.DataFrame:
    """
    The function performs each of the following steps:
    1. Compute the minimum variance portfolio weight mvp_weights for the input Sigma_est. 
        The function can handle positive definite variance-covariance matrices of arbitrary dimensions N x N.
    2. Compute the eﬀicient portfolio weights efp_weights for the inputs Sigma_est and mu_est 
      that delivers two times the expected return of the minimum variance portfolio weight.
    3. Make use of the two-mutual fund theorem to characterize a range of portfolio weights on the eﬀicient frontier: 
      Specifically, compute the weights of a sequence of portfolios which are combinations of the minimum variance portfolio weight
        and the eﬀicient portfolio, c_weights = c * mvp_weights  + (1 - c) * efp_weights where c ∈ {-0.1, ... , 1.2}
    
      Args: 
        mu_est (np.array): N x 1 return matrix
        sigma_est (np.array): N x N variance-covariance matrix
      Returns: 
        df: with column c which is the weight of the minimum variance portfolio and N corresponding columns with the weights 
          of each asset
    """
    class results: pass
    results.inputs = {}
    results.inputs['mu'] = mu_est
    results.inputs['sigma'] = sigma_est
    results.inputs['yearly_factor'] = yearly_factor

    N = mu_est.shape[0]
    if sigma_est.shape[0] != N: 
        raise ValueError('The size length of vector mu_est should be the same as for sigma_est')
    iota = np.ones(N)
    sigma_inv = np.linalg.inv(sigma_est) 

    #----- minimum variance portfolio
    mvp_weights = sigma_inv @ iota
    mvp_weights = mvp_weights/mvp_weights.sum()
    mvp_return,mvp_volatility =  calc_return_std(mvp_weights,mu,sigma_est,yearly_factor)
    print(f'Return of the minimum variance portfolio is: {mvp_return:.2f} and its volatility is {mvp_volatility:.2f}')
    results.mvp_weights = mvp_weights  # store minimum variance portfolio weights in object

    #----- efficient frontier portfolio
    mu_bar = mvp_return*2
    C = iota.T @ sigma_inv @ iota
    D = iota.T @ sigma_inv @ mu_est
    E = mu_est.T @ sigma_inv @ mu_est
    lambda_tilde = 2 * (mu_bar - D/C) / (E-D**2/C)
    efp_weights = mvp_weights + lambda_tilde/2 * (sigma_inv@mu_est - D* mvp_weights ) 
    efp_return,efp_vol =  calc_return_std(efp_weights,mu,sigma_est,yearly_factor)
    print(f'Return of the efficient frontier portfolio is: {efp_return:.2f} and its volatility is {efp_vol:.2f}')
    results.efp_weights = efp_weights # store efficient frontier portfolio weights in object

    #----- mutual fund theorem
    a = np.linspace(-0.2, 1.2, 121)
    res = pd.DataFrame(columns=["mu", "sd"], index=a).astype(float)
    for i in a:
        w = i*mvp_weights+(1-i)*efp_weights
        for j in range(len(w)):
          res.loc[i, f"w_{j+1}"] = w[j]  # Assign each element of w to a named column
        res.loc[i, "mu"] = (w.T @ mu)*yearly_factor
        res.loc[i, "sd"] = np.sqrt(w.T @ sigma @ w)*np.sqrt(yearly_factor)
    
    results.res = res   # store dataframe in object 

    return results
```

```{python}
cef = compute_efficient_frontier(mu_est=mu,sigma_est=sigma,yearly_factor=12)

efpRet, efpVol = calc_return_std(weights=cef.efp_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])
efpSR = efpRet/efpVol

mvpRet, mvpVol = calc_return_std(weights=cef.mvp_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])
mvpSR = mvpRet/mvpVol

x = 'increases' if not (mvpSR > efpSR) else 'decreases'
```

The minimum variance portfolio has an expected return of `{python} (mvpRet*100).round(2)` and a volatility of `{python} (mvpVol*100).round(2)`. While the volatility of the efficient portfolio that delivers two times the expected return of the minimum variance is `{python} (efpVol*100).round(2)`. We notice that the Sharpe ratio `{python} x` from `{python} mvpSR.round(2)` to `{python} efpSR.round(2)`.


```{python}
#---- tangency portfolio
# ¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿
#       connsider if there is a better way
# ????????????????????????????????????????????????
d = np.vstack((cef.inputs['sigma'],np.ones(27)))
c = np.append(cef.inputs['mu'],0)
e = np.hstack((d,c.reshape(c.shape[0],1)))
q = np.append(np.zeros(cef.inputs['mu'].shape[0]),1)
tan_weights = np.linalg.inv(e) @ q
tan_weights = tan_weights[:-1]
tanRet, tanVol = calc_return_std(weights=tan_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])

# sharpe-ratio
sharpeRatio = tanRet/tanVol

vol = np.linspace(0,tanVol,101)
x = np.linspace(0,1,101)
ret = np.nan + np.zeros(vol.shape[0])
for i, v in enumerate(x):
   ret[i] = tanRet * v
tanLine = pd.DataFrame((vol,ret),index=['vol','ret']).T

res_figure = (
  ggplot(cef.res, aes(x="sd", y="mu")) +
  geom_point() + 
  geom_line(tanLine, aes(x='vol',y='ret'))+
  geom_point(
    pd.DataFrame({"mu": [mvpRet, efpRet,tanRet],"sd":[mvpVol, efpVol,tanVol]}),
    size=4, 
    color='darkblue',
    ) +
  geom_point(
    pd.DataFrame({"mu": cef.inputs['mu']*12,
                  "sd": np.sqrt(np.diag(cef.inputs['sigma'])) * np.sqrt(12)
                  })
  ) +
  labs(x="Annualized standard deviation",
       y="Annualized expected return",
       title="Efficient frontier for DOW index constituents") +
  scale_x_continuous(labels=percent_format()) +
  scale_y_continuous(labels=percent_format())
)
```

```{python}
# | output : true
res_figure
```

**Exercise 4**  
The efficient tangency portfolio weights are displayed below:
```{python}
# | output : true
print(tan_weights.round(2))
```

In theory, the efficient tangent portoflio should just be the market portfolio. As such, the weights of the efficient tangent portfolio should be given by: $Weight_{S_i}=\frac{Price_{S_i}}{Marketsize}$. Therefore, there would be no shorting needed to obtain the efficient tangent portfolio. However, we find that the efficient portfolio indeed contains significant shorting of stocks. This is because we are only working with a small sample of the entire market, and that some of the analyzed stocks have performed poorly in the sample period. A stock with expected negative returns should be shorted, and that is what happens in our portfolio when we construct it based on past returns.

Transaction costs and estimation dificulties are the potential issues when implementing the market portfolio in reality. To implement the market portfolio in reality, one would have to constantly update the portfolio weights. The stock prices are constantly changing and so is the optimal weight of the market portfolio. Transaction costs include expenses to the stock exchange and costs associated with frequent trading of low volume stocks that often have high bid-ask spreads. Furthermore, estimating the optimal portfolio weight of all stocks and updating that estimation frequently requires expensive data-access. As such, it is often cheaper for an investor to buy an MSCI World ETF, which mimics the market portfolio.

The maximum attainable Sharpe ratio is the Sharpe ratio of the capital market line. On the capital market line, stocks have the highest possible expected return for a given volatility. As such, the Sharpe ratio of the market portfolio will be higher than individual assets, which is also clearly illustrated in the figure above.

**Exercise 5**  
Provided with the function simulate_returns, we're able to simulate monthly returns of stocks for a given number of stocks. The function takes three parameters: periods, mu and sigma. Firstly, periods define the number of monthly return for each stock the function should return. Secondly, mu define the mean of each draw which comes from a normal distribution. Thirdly, sigma is the variance-covariance which is used to define the standard deviation for the disitribution. But also the covariance comes into play as the function np.random.multivariate_normal takes the covariance into account. In our implentation of the simulation draw, we set the seed to 100.

**Exercise 6 and 7**  
```{python}
# simulating returns 
def simulate_returns(periods=200,
                     expected_returns=mu,
                     covariance_matrix=sigma):
    """
        periods (int): Number of periods
        expected_returns (array-like): Expected returns for each asset
        covariance_matrix (array-like): Covariance matrix of returns
    """
    return np.random.multivariate_normal(
       mean=expected_returns, 
       cov=covariance_matrix, 
       size=periods
    )

def calc_eff_tang_port(x):
  d = np.vstack((x.inputs['sigma'],np.ones(27)))
  c = np.append(x.inputs['mu'],0)
  e = np.hstack((d,c.reshape(c.shape[0],1)))
  q = np.append(np.zeros(x.inputs['mu'].shape[0]),1)
  tan_weights = np.linalg.inv(e) @ q
  tan_weights = tan_weights[:-1]
  return tan_weights 


simLength = 100
simdraws = {i:{} for i in range(simLength)}
np.random.seed(100)
for i in range(simLength):
  if i % 10==0: print(f'{i+1} out of {simLength}')
  draw1 = pd.DataFrame(simulate_returns(periods=200,expected_returns=cef.inputs['mu'],covariance_matrix=cef.inputs['sigma']))
  mu_sim_est = np.array(draw1.mean()).T
  sigma_sim_est = np.array(draw1.cov())
  eff = compute_efficient_frontier(mu_est=mu_sim_est,sigma_est=sigma_sim_est,yearly_factor=12)
  sim_df = eff.res
  sim_df['sim_draw_no'] = i
  tan_weights = calc_eff_tang_port(x=eff)
  tanRet, tanVol = calc_return_std(weights=tan_weights,mu=eff.inputs['mu'],sigma_matrix=eff.inputs['sigma'],factor=eff.inputs['yearly_factor'])
  simdraws[i] = {'Frontier':sim_df,
                          'Tangency Weights': tan_weights,
                          'Sharpe Ratio': tanRet/tanVol,
                          'input':{'mu':mu_sim_est,
                                   'sigma':sigma_sim_est,
                                   'data':draw1}}

sim_df = pd.concat([simdraws[i]['Frontier'] for i in range(simLength)])
# plot of first simulatioj
res_figure2 = (
  ggplot(sim_df.loc[sim_df['sim_draw_no']==0], aes(x="sd", y="mu")) +
  geom_point() + 
  geom_point(cef.res, colour='red') + 
  labs(x="Annualized standard deviation",
       y="Annualized expected return",
       title="Efficient frontier for true parameters and simulated") +
  scale_x_continuous(labels=percent_format()) +
  scale_y_continuous(labels=percent_format())
)
# plot of all 100 simulations
res_figure3 = (
    ggplot(sim_df, aes(x="sd", y="mu",group='sim_draw_no')) +
    geom_point(alpha=0.05)  # Plot first element with label
    +geom_point(cef.res.assign(sim_draw_no = -1),alpha=1,colour='black') + 
    labs(x="Annualized standard deviation",
        y="Annualized expected return",
        title="Efficient frontier for all simulations") 
)
```
```{python}
# | output : true
res_figure2
```
```{python}
# | output : true
res_figure3
```

This section explores the deviations between the theoretical efficient frontier and its estimates obtained through sample data. We achieve this by simulating multiple sample return series and constructing the corresponding efficient frontiers.

*Simulation Process*:

1.  We employ a multivariate normal distribution to generate 100 hypothetical samples of asset returns, each with a size of 200 periods. The parameters for the distribution are set to the expected returns and covariance matrix of the actual assets.

2.  For each simulated sample, we estimate the sample mean and sample covariance matrix.

3.  Utilizing these estimated parameters, we compute the corresponding efficient frontier.

4.  Additionally, the tangency portfolio weights and Sharpe Ratio are calculated for each simulated efficient frontier.

*Analysis of the Results*:

1.  We visually compare the first simulated efficient frontier with the theoretically optimal frontier obtained from the population parameters. This initial comparison highlights the departure of the estimated frontier due to sampling error.

2.  Subsequently, we plot all 100 simulated efficient frontiers alongside the true frontier. This visualization reveals the distribution and variability of the estimated frontiers around the theoretical optimum.

*Observations and Inferences*:

The simulated frontiers demonstrate a deviation from the true efficient frontier. This discrepancy arises due to the inherent uncertainty associated with using sample estimates of the population mean and covariance.

In conclusion, this simulation exercise underscores the importance of considering the limitations of sample-based estimates when constructing the efficient frontier. While the true frontier represents the optimal allocation for maximizing expected return for a given level of risk, practical implementation relies on estimates derived from available data. The presented results emphasize the uncertainty associated with these estimates and the potential deviations from the true efficient frontier.

**Exercise 8 & 9**  
We compute the efficient tangent portfolio for each simulated return sample, assuming a zero risk-free rate and utilizing the estimated covariance matrix $\hat{\Sigma}$ and mean vector $\hat{\mu}$. The portfolio weights are derived as earlier described. With these weights, we calculate the annualized Sharpe ratio using true parameters $\mu$ and $\Sigma$, employing the formula $\text{SR} = \sqrt{12} \frac{\omega^{tg}\mu}{\sqrt{\omega^*{tg}\Sigma \omega^*_{tg}}}$. The resultant Sharpe ratios are stored and visualized in a histogram, providing insight into portfolio performance variability across simulations.

The histogram shows Sharpe Ratios for the 100 simulated tangency portfolios. The red dashed line marks the true Sharpe Ratio derived from true parameters.
We note that for most of the simulations, the sharpe ratios are below the one derived with true parameters. 
```{python}
# | output : true
# plot histogram of sharpe ratios
(
    ggplot(pd.DataFrame([simdraws[i]['Sharpe Ratio'] for i in range(simLength)],columns=['Sharpe Ratio'])) + 
    aes(x = 'Sharpe Ratio') +
    geom_histogram(binwidth=0.1) +
    geom_vline(xintercept=tanRet/tanVol,colour='red',linetype='dashed') + 
    labs(x="Shapre Ratio",
        y="Freq",
        title="Share")
).draw()
```

**Exercise 10**  
When we increase the sample size periods, our results asymptotically moves towards their true value. 

The figure shows that the estimated frontiers are not on par with the true efficient frontier. This is because the efficient market portfolio is derived from past data which is not a precise indicator of future returns and volatility.

Unfortunately we where not able to find any alternative allocation strategies to improve the estimates' shortfall. Therefore, we where not able to complete the rest of exercise 10.