---
title: Mandatory Assignment 1
author: Asbjørn Fyhn & Emil Beckett Kolko
date: '2024-03-08'
execute:
  echo: false
  warning: false
  output: false
format:
  pdf:
    documentclass: article
    number-sections: true
    colorlinks: true
    geometry:
      - top=20mm
      - left=20mm
      - bottom=20mm
      - right=20mm
    cite-method: natbib
    fontsize: 12pt
jupyter: python3
---

In the following, we complete the exercises for Mandatory Assignment 1.


<!-- Exercise 1 -->

```{python}

import pandas as pd 
import numpy as np
import yfinance as yf
from datetime import datetime as dt
from plotnine import *
from mizani.formatters import percent_format

seed = 100
np.random.seed(seed)
# define list of tickers
tickerlist = ['UNH', 'MSFT', 'GS', 'HD', 'CAT', 'CRM', 'MCD',
               'V', 'AMGN', 'TRV', 'AXP', 'BA', 'HON', 'JPM',
                 'IBM', 'AAPL', 'AMZN', 'JNJ', 'PG', 'CVX',
                   'MRK', 'DIS', 'NKE', 'MMM', 'KO', 'WMT', 
                   'DOW', 'CSCO', 'INTC', 'VZ']
return_col = 'ret' # alternatively use 'ret' to get standard returns
```

```{python}

# inputdf = yf.download(tickers=tickerlist,period='25y', interval="1d") 
inputdf = pd.read_pickle(r'DJ_comp.pkl')
# transform the dataset
df = (inputdf
      .get('Adj Close')
      .stack()
      .reset_index()
      .rename(columns={'Date':'date','level_1':'ticker',0:'adj_close'})
      .set_index('date')
      .groupby('ticker')['adj_close']
      .resample('m')
      .last()
      .reset_index()
      .assign(date=lambda x: x['date'].dt.strftime('%Y-%m-%d'))  # Convert date to string
      .query("date >= '2000-01-01'")  
      .query("date <= '2023-12-31'")
      )

# remove all tickers where there is no data for each month 
df = (df
  .groupby(["ticker"])
  .apply(lambda x: x.assign(counts=x["adj_close"].dropna().count()))
  .reset_index(drop=True)
  .query("counts == counts.max()")
  .drop(columns='counts')
  .assign(ret=lambda x: x["adj_close"].pct_change())
  .assign(log_return = lambda x: np.log(x['adj_close']/x['adj_close'].shift(1)) )
)

# check that we have 27 tickers
no_of_tickers = int(df['ticker'].unique().size)
#print(f'The number of tickers in the dataset: { no_of_tickers}')

#
mu = np.array(df.groupby('ticker')[return_col].mean()).T
sigma = np.array(df.pivot(index='date',columns='ticker',values=return_col).cov())

# Calculate Sharpe ratio for each stock
sharpe_ratio = np.sqrt(12)*(mu - 0) / np.sqrt(np.diag(sigma))
# Print the Sharpe ratio
sr_high = df.groupby('ticker')['ticker'].first().iloc[sharpe_ratio.argmax()]
```

**Exercise 1 and 2**  <!-- The code for this exercise is found above -->  
We retrieve the daily adjusted prices of all the constituents of the Dow Jones index from January 1, 2000, to December 31, 2023 from Yahoo!Finance and remove all tickers that do not have continuous trading history throughout the period. We calculate the monthly returns of each ticker and use these series to calculate a vector of the average monthly returns $\mu$ and a variance-covariance matrix $\Sigma$. To calculate the Sharpe ratios (S), we use the formula: $S_i=\frac{r_i}{\sigma_i}$, where $r_i$ is the annualized return and $\sigma_i$ is the annualized standard deviation for ticker i. The stock with the highest Sharpe ratio is `{python} sr_high` with a ratio of `{python} sharpe_ratio.max().round(3)`.

```{python}

def calc_return_std(weights, mu, sigma_matrix, factor):
  """
  Calculate the expected return and standard deviation of a portfolio.

  Parameters:
  weights (numpy.ndarray): The weights of the assets in the portfolio.
  mu (numpy.ndarray): The expected returns of the assets.
  sigma_matrix (numpy.ndarray): The covariance matrix of the assets.
  factor (float): A scaling factor.

  Returns:
  tuple: A tuple containing the expected return and standard deviation of the portfolio.
  """
  return_vec = mu.T @ weights * factor 
  vol = np.sqrt(weights.T @ sigma_matrix @ weights) * np.sqrt(factor)
  return return_vec, vol
```

**Exercise 3**  
First, we create a function 'compute_efficient_frontier' which returns an object with the inputs consisting of a vector of the estimated expected return, the estimated variance-covariance matrix and a factor that is used to annualize the return, the minimum variance portfolio, the efficient portfolio that delivers two times the expected return of the minimum variance portfolio, and, lastly, the efficient frontier. We have calculated the inputs as follows:

* The sample average return vector: $\hat{\mu}=\frac{1}{T}\Sigma^T_{t=1}r_t$
* The variance co-variance matrix: $\hat{\Sigma}=\frac{1}{T-1}\Sigma^T_{t=1}(r_t-\hat{\mu})(r_t-\hat{\mu})'$
* The factor is just 12, because we are annualizing monthly data
* We define the minimum variance portfolio as follows: $\omega_{mvp}=\text{arg\:min}\:\omega'\Sigma\omega\:\:s.t.\:\Sigma^N_{i=1}\omega_i=1$,  
where the solution is $\omega_{mvp}=\frac{\Sigma^{-1}\iota}{\iota'\Sigma^{-1}\iota}$  
* And the efficient portfolio as follows: $\omega_{eff}(\bar{\mu})=\text{arg\:min}\:\omega'\Sigma\omega\:\:s.t.\:\omega'\iota=1\:\text{and}\:\omega'\mu\geq\bar{\mu}$,  
where the solution is $\omega_{eff}(\bar{\mu})=\omega_{mvp}+\frac{\tilde{\lambda}}{2}\left(\Sigma^{-1}\mu-\frac{D}{C}\Sigma^{-1}\iota\right)$,  
where $C\equiv\iota'\Sigma^{-1}\iota,\:D\equiv\iota'\Sigma^{-1}\mu,\:E\equiv\mu'\Sigma^{-1}\mu,\:\:\text{and}\:\tilde{\lambda}=2\frac{\bar{\mu}-D/C}{E-D^2/C}$  
* Lastly, in accordance with the mutual fund theorem, we compute the efficient frontier with a linear combination of the risk free rate (0 in this case) and the efficient market portfolio

```{python}

def mean_variance_portfolio(sigma_inv):
  """

  """
  N = sigma_inv.shape[0]
  iota = np.ones(N)
  mvp_weights = sigma_inv @ iota
  mvp_weights = mvp_weights/mvp_weights.sum()
  return mvp_weights


def compute_efficient_frontier(mu_est: np.array, sigma_est: np.array, yearly_factor: int=1, verbose=False) -> pd.DataFrame:
    """
    The function performs each of the following steps:
    1. Compute the minimum variance portfolio weight mvp_weights for the input Sigma_est. 
        The function can handle positive definite variance-covariance matrices of arbitrary dimensions N x N.
    2. Compute the eﬀicient portfolio weights efp_weights for the inputs Sigma_est and mu_est 
      that delivers two times the expected return of the minimum variance portfolio weight.
    3. Make use of the two-mutual fund theorem to characterize a range of portfolio weights on the eﬀicient frontier: 
      Specifically, compute the weights of a sequence of portfolios which are combinations of the minimum variance portfolio weight
        and the eﬀicient portfolio, c_weights = c * mvp_weights  + (1 - c) * efp_weights where c ∈ {-0.1, ... , 1.2}
    
      Args: 
        mu_est (np.array): N x 1 return matrix
        sigma_est (np.array): N x N variance-covariance matrix
      Returns: 
        df: with column c which is the weight of the minimum variance portfolio and N corresponding columns with the weights 
          of each asset
    """
    class results: pass
    results.inputs = {}
    results.inputs['mu'] = mu_est
    results.inputs['sigma'] = sigma_est
    results.inputs['yearly_factor'] = yearly_factor

    N = mu_est.size
    if sigma_est.shape[0] != N: 
        raise ValueError('The size length of vector mu_est should be the same as for sigma_est')
    iota = np.ones(N)
    sigma_inv = np.linalg.inv(sigma_est) 

    #----- minimum variance portfolio
    mvp_weights = mean_variance_portfolio(sigma_inv=sigma_inv)
    mvp_return,mvp_volatility =  calc_return_std(mvp_weights,mu,sigma_est,yearly_factor)
    
    results.mvp_weights = mvp_weights  # store minimum variance portfolio weights in object

    #----- efficient frontier portfolio
    return_multiple = 2
    mu_bar = return_multiple * mvp_weights.T @ mu
    C = iota.T @ sigma_inv @ iota
    D = iota.T @ sigma_inv @ mu_est
    E = mu_est.T @ sigma_inv @ mu_est
    lambda_tilde = 2 * (mu_bar - D/C) / (E-D**2/C)
    efp_weights = mvp_weights + lambda_tilde/2 * (sigma_inv@mu_est - D* mvp_weights ) 
    efp_return,efp_vol =  calc_return_std(efp_weights,mu,sigma_est,yearly_factor)
    results.efp_weights = efp_weights # store efficient frontier portfolio weights in object

    if verbose: 
      print(f'Return of the minimum variance portfolio is: {mvp_return:.2f} and its volatility is {mvp_volatility:.2f}')
      print(f'Return of the efficient frontier portfolio is: {efp_return:.2f} and its volatility is {efp_vol:.2f}')

    #----- mutual fund theorem
    a = np.linspace(-0.2, 1.2, 121)
    res = pd.DataFrame(columns=["mu", "sd"], index=a).astype(float)
    for i in a:
        w = i*mvp_weights+(1-i)*efp_weights
        for j in range(len(w)):
          res.loc[i, f"w_{j+1}"] = w[j]  # Assign each element of w to a named column
        res.loc[i, "mu"] = (w.T @ mu)*yearly_factor
        res.loc[i, "sd"] = np.sqrt(w.T @ sigma @ w)*np.sqrt(yearly_factor)
    
    results.res = res   # store dataframe in object 

    return results
```

```{python}

cef = compute_efficient_frontier(mu_est=mu,sigma_est=sigma,yearly_factor=12)

efpRet, efpVol = calc_return_std(weights=cef.efp_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])
efpSR = efpRet/efpVol

mvpRet, mvpVol = calc_return_std(weights=cef.mvp_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])
mvpSR = mvpRet/mvpVol

x = 'increases' if not (mvpSR > efpSR) else 'decreases'
```

The minimum variance portfolio has an expected return of `{python} (mvpRet*100).round(2)` and a volatility of `{python} (mvpVol*100).round(2)`. While the volatility of the efficient portfolio that delivers two times the expected return of the minimum variance is `{python} (efpVol*100).round(2)`. We notice that the Sharpe ratio `{python} x` from `{python} mvpSR.round(2)` to `{python} efpSR.round(2)`.

```{python}

#---- tangency portfolio
rf = 0
sigma_inv = np.linalg.inv(sigma) 
tan_weights =  sigma_inv@(mu - rf) / (np.ones(mu.shape) @ sigma_inv @ (mu - rf))
tanRet, tanVol = calc_return_std(weights=tan_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])

# sharpe-ratio
sharpeRatio = tanRet/tanVol

vol = np.linspace(0,tanVol,101)
x = np.linspace(0,1,101)
ret = np.nan + np.zeros(vol.shape[0])
for i, v in enumerate(x):
   ret[i] = tanRet * v
tanLine = pd.DataFrame((vol,ret),index=['vol','ret']).T

res_figure = (
  ggplot(cef.res, aes(x="sd", y="mu")) +
  geom_point() + 
  # geom_line(tanLine, aes(x='vol',y='ret'))+
  geom_point(
    pd.DataFrame({"mu": [mvpRet, efpRet],"sd":[mvpVol, efpVol]}),
    size=4, 
    color='darkblue',
    ) +
  geom_point(
    pd.DataFrame({"mu": cef.inputs['mu']*12,
                  "sd": np.sqrt(np.diag(cef.inputs['sigma'])) * np.sqrt(12)
                  })
  ) +
  labs(x="Annualized standard deviation",
       y="Annualized expected return",
       ) +
  scale_x_continuous(labels=percent_format()) +
  scale_y_continuous(labels=percent_format()) +
  theme_minimal() + 
  theme(legend_position=(0.15,0.9),legend_title=element_blank(),legend_direction='vertical')
)
```

```{python}
#| output: true
#| tbl-cap: "Portfolio Statistics"
#| fig-height: 4
#| fig-width: 6
pd.DataFrame({'Tangency Portfolio': [tanRet, tanVol, tanRet/tanVol],
              'Efficient Frontier Portfolio': [efpRet, efpVol, efpSR],
              'Minimum Variance Portfolio': [mvpRet, mvpVol, mvpSR]},
             index=['Return', 'Volatility', 'Sharpe Ratio']).round(2)
```

```{python}
#| output: true
#| fig-cap: "Efficient frontier for DOW index constituents"
#| fig-height: 4
#| fig-width : 6

res_figure
```

**Exercise 4**  
We calculate the eﬀicient tangency portfolio weights as $w_{tgc}=\frac{\Sigma^-\mu}{\iota'\Sigma^-\mu}$ under the assumption that the risk free rate is 0. The weights are presented in @fig-tw below.

```{python}
#| output: true
#| label: fig-tw
#| fig-cap : "The weights of the Efficient Tangency Portfolio"
#| fig-align : 'center'
#| fig-pos: 'h'
# Create a DataFrame with the weights of the Efficient Tangency Portfolio
w_tgc = pd.DataFrame({'Ticker': df['ticker'].unique(), 'Weight': tan_weights})

# Create the plot with rotated text within each bar
(ggplot(w_tgc, aes(x='Ticker', y='Weight'))
        + geom_bar(stat='identity', fill='skyblue', width=0.7)
        + geom_text(aes(label=round(w_tgc['Weight'], 3)), angle=90, va='center', color='black', size=10)
        + labs(x='Ticker', y='Weight')
        + theme_minimal()
        + theme(axis_text_x=element_text(angle=90, vjust=0.5, hjust=0.5))
        )
```



The tangency portfolio weights seem well-balanced considering the limited diversification opportunities in the estimation. Poorly performing stocks are shorted to increase the weight of well performing stocks. However, the portfolio weights are not consistent under CAPM assumptions. Here, the eﬀicient tangent portfolio is the market portfolio where all stocks are weighted according to their market values: $w_i=\frac{P_i}{\Sigma^n_{j=1}P_j}$, where $w_i$ is the weight of stock i, $P_i$ is the price of stock i, and $\Sigma^n_{j=1}P_j$ is the sum of the price of all stocks (the value of the entire market). Therefore, theoretically, there should be no shorting needed to obtain the efficient tangent portfolio. However, as @fig-tw shows, we find that it requires significant shorting of stocks to obtain the tangent portfolio. We did not expect a result in accordance with CAPM because our portfolio is composed of only 27 large-cap stocks which is a small subset of the entire market of which the CAPM theory builds upon.

When implementing this efficient tangent portfolio in reality, one should consider issues such as transactions costs and estimation issues. The portfolio weights must be updated constantly because the stock prices are fluctuating, which results in high transactions costs. Furthermore, both $\mu$ and $\Sigma$ used for optimization are subject to estimation uncertainty, increasing risk and deviations from the expected outcomes.

However, the efficient tangent portfolio has the maximum attainable Sharpe ratio of 1.38 when comprising a portfolio of only the Dow Jones 30 index. The Sharpe Ratio is significantly higher than that of AAPL, which makes sense as AAPL is only one single stock. AAPL is included in the efficient tangent portfolio, so we could at least get that Sharpe Ratio. Instead, the efficient tangent portfolio optimizes the risk/return tradeoff across all 27 stocks.

**Exercise 5**  
Provided with the function simulate_returns, we're able to simulate monthly returns of stocks for a given number of stocks. The function takes three parameters: periods, mu and sigma. Firstly, periods define the number of monthly return for each stock the function should return. Secondly, mu define the mean of each draw which comes from a normal distribution. Thirdly, sigma is the variance-covariance which is used to define the standard deviation for the distribution. But also the covariance comes into play as the function np.random.multivariate_normal takes the covariance into account. In our implementation of the simulation draw, we set the seed to 100.

**Exercise 6**  

```{python}

# simulating returns 
def simulate_returns(periods=200,
                     expected_returns=mu,
                     covariance_matrix=sigma):
    """
        periods (int): Number of periods
        expected_returns (array-like): Expected returns for each asset
        covariance_matrix (array-like): Covariance matrix of returns
    """
    return np.random.multivariate_normal(
       mean=expected_returns, 
       cov=covariance_matrix, 
       size=periods
    )

def calc_eff_tang_port(mu, sigma, rf=0):
  """
  Calculates the weights of the efficient tangent portfolio.

  Parameters:
  - sigma: The covariance matrix of asset returns.
  - mu: The expected returns of the assets.
  - rf: The risk-free rate of return (default is 0).

  Returns:
  - tan_weights: The weights of the efficient tangent portfolio.

  """
  sigma_inv = np.linalg.inv(sigma) 
  tan_weights =  sigma_inv@(mu - rf) / (np.ones(mu.shape) @ sigma_inv @ (mu - rf))

  return tan_weights

def sort_portfolio(mu):
  sorted_mu = np.sort(mu)[::-1]
  sort_weight = sorted_mu/np.sum(mu)
  return sort_weight

def do_single_simulation():
  """
  This function performs a single simulation by generating random returns based on the given parameters and computes the efficient frontier, tangency weights, Sharpe ratio, and other relevant information.

  Returns:
  - Frontier: DataFrame containing the efficient frontier.
  - Tangency Weights: Array of weights for the tangency portfolio.
  - Sharpe Ratio: The Sharpe ratio of the tangency portfolio.
  - input: Dictionary containing the input parameters used in the simulation, including the estimated mean returns (mu), covariance matrix (sigma), and the simulated returns data (data).
  """
  draw = simulate_returns(periods=200,expected_returns=cef.inputs['mu'],covariance_matrix=cef.inputs['sigma'])
  mu_sim_est = np.mean(draw,axis=0).T
  sigma_sim_est = np.cov(draw,rowvar=False)
  eff = compute_efficient_frontier(mu_est=mu_sim_est,sigma_est=sigma_sim_est,yearly_factor=12,verbose=False)
  sim_df = eff.res

  sim_tan_weights = calc_eff_tang_port(mu=mu_sim_est, sigma=sigma_sim_est, rf=0)
  sim_tanRet, sim_tanVol = calc_return_std(weights=sim_tan_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])
  return {'Frontier':sim_df,
                          'Tangency Weights': sim_tan_weights,
                          'Sharpe Ratio': sim_tanRet/sim_tanVol,
                          'input':{'mu':mu_sim_est,
                                   'sigma':sigma_sim_est,
                                   'data':draw}}
```

```{python}
#| output: true
#| label : fig-oneobservedfrontier
#| fig-cap: "Single observed and true frontier"


# plot of first simulatioj
single_sim_df = do_single_simulation()['Frontier']

plot_df = pd.concat([single_sim_df.assign(true='Simulated'),cef.res.assign(true='True')])

res_figure2 = (
  ggplot(plot_df, aes(x="sd", y="mu",color='true'),) +
  geom_point() + 
  labs(x="Annualized standard deviation",
       y="Annualized expected return",) +
  scale_x_continuous(labels=percent_format()) +
  scale_y_continuous(labels=percent_format()) +
  theme_minimal() + 
  theme(legend_position=(0.15,0.9),legend_title=element_blank(),legend_direction='vertical')
)
res_figure2

```

**Exercise 7**  

```{python}
simLength = 100
simdraws = {i:{} for i in range(simLength)}

for i in range(simLength):
  simdraws[i] = do_single_simulation()
  simdraws[i]['Frontier']['sim_draw_no'] = i
```

```{python}
#| output: true
#| label : fig-simulationfrontiers
#| fig-cap: "Observed frontiers and true frontier"

sim_df = pd.concat([simdraws[i]['Frontier'] for i in range(simLength)])
(
    ggplot(sim_df, aes(x="sd", y="mu",group='sim_draw_no')) +
    geom_point(alpha=0.05)  # Plot first element with label
    +geom_point(cef.res.assign(sim_draw_no = -1),alpha=1,colour='#57d3db') + 
    labs(x="Annualized standard deviation",
        y="Annualized expected return",
        ) +
        theme_minimal() +
        theme(legend_position=(0.15,0.9),legend_title=element_blank(),legend_direction='vertical')
)
```

This section explores the deviations between the theoretical efficient frontier and its estimates obtained through sample data. We achieve this by simulating multiple sample return series and constructing the corresponding efficient frontiers.

*Simulation Process*:

1.  We employ a multivariate normal distribution to generate 100 hypothetical samples of asset returns, each with a size of 200 periods. The parameters for the distribution are set to the expected returns and covariance matrix of the actual assets.

2.  For each simulated sample, we estimate the sample mean and sample covariance matrix.

3.  Utilizing these estimated parameters, we compute the corresponding efficient frontier.

4.  Additionally, the tangency portfolio weights and Sharpe ratio are calculated for each simulated efficient frontier.

*Analysis of the Results*:

1.  We visually compare the first simulated efficient frontier with the theoretically optimal frontier obtained from the population parameters. This initial comparison highlights the departure of the estimated frontier due to sampling error.

2.  Subsequently, we plot all 100 simulated efficient frontiers alongside the true frontier. This visualization reveals the distribution and variability of the estimated frontiers around the theoretical optimum.

*Observations and Inferences*:

The simulated frontiers demonstrate a deviation from the true efficient frontier. This discrepancy arises due to the inherent uncertainty associated with using sample estimates of the population mean and covariance.

In conclusion, this simulation exercise underscores the importance of considering the limitations of sample-based estimates when constructing the efficient frontier. While the true frontier represents the optimal allocation for maximizing expected return for a given level of risk, practical implementation relies on estimates derived from available data. The presented results emphasize the uncertainty associated with these estimates and the potential deviations from the true efficient frontier.

**Exercise 8 & 9**  
We compute the efficient tangent portfolio for each simulated return sample, assuming a zero risk-free rate and utilizing the estimated covariance matrix $\hat{\Sigma}$ and mean vector $\hat{\mu}$. The portfolio weights are derived as earlier described. With these weights, we calculate the annualized Sharpe ratio using true parameters $\mu$ and $\Sigma$, employing the formula $\text{SR} = \sqrt{12} \frac{\omega^{tg}\mu}{\sqrt{\omega^*{tg}\Sigma \omega^*_{tg}}}$. The resultant Sharpe ratios are stored and visualized in a histogram, providing insight into portfolio performance variability across simulations.

The histogram shows Sharpe ratios for the 100 simulated tangency portfolios. The red dashed line marks the true Sharpe ratio derived from true parameters.
We note that for most of the simulations, the Sharpe ratios are below the one derived with true parameters. 

```{python}
#| output: true
#| label : fig-histsharperatios
#| fig-cap: "Distribution of sharpe-ratios"

# plot histogram of sharpe ratios
sharpe_df = pd.DataFrame([simdraws[i]['Sharpe Ratio'] for i in range(simLength)],columns=['Sharpe Ratio'])

(
    ggplot(sharpe_df) + 
    aes(x = 'Sharpe Ratio') +
    geom_histogram(binwidth=0.01) +
    geom_vline(xintercept=tanRet/tanVol,colour='red',linetype='dashed') + 
    labs(x="Sharpe Ratio",
        y="Freq",
        title="Share") +
    theme_minimal() +
    theme(legend_position=(0.15,0.9),legend_title=element_blank(),legend_direction='vertical')
).draw()
```

**Exercise 10**  
When we increase the sample size periods, our results asymptotically move towards their true value. 

The figure shows that the estimated frontiers are not on par with the true efficient frontier. This is because the efficient market portfolio is derived from past data which is not a precise indicator of future returns and volatility.

Unfortunately we were not able to find any alternative allocation strategies to improve the estimates' shortfall. Therefore, we were not able to complete the rest of exercise 10.


```{python}
#| output: true

# ewp is the weight of the equal weighted portfolio
ewp = np.ones(mu.size)/mu.size

print(calc_return_std(ewp,mu, sigma,12))


```
