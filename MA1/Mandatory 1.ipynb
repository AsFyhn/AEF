{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Mandatory Assignment 1\"\n",
        "author: \"Asbjørn Fyhn & Emil Beckett Kolko\"\n",
        "date: \"2024-03-08\"\n",
        "execute: \n",
        "  echo: false\n",
        "  warning: false\n",
        "format:\n",
        "  pdf: \n",
        "    number-sections: true\n",
        "    colorlinks: true\n",
        "    geometry:\n",
        "      - top=20mm\n",
        "      - left=20mm\n",
        "      - bottom=20mm\n",
        "      - right=20mm\n",
        "    cite-method: natbib\n",
        "    fontsize: 12pt\n",
        "bibliography: references.bib\n",
        "---"
      ],
      "id": "7ee874df"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from datetime import datetime as dt\n",
        "from plotnine import *\n",
        "from mizani.formatters import percent_format\n",
        "\n",
        "# define list of tickers\n",
        "tickerlist = ['UNH', 'MSFT', 'GS', 'HD', 'CAT', 'CRM', 'MCD',\n",
        "               'V', 'AMGN', 'TRV', 'AXP', 'BA', 'HON', 'JPM',\n",
        "                 'IBM', 'AAPL', 'AMZN', 'JNJ', 'PG', 'CVX',\n",
        "                   'MRK', 'DIS', 'NKE', 'MMM', 'KO', 'WMT', \n",
        "                   'DOW', 'CSCO', 'INTC', 'VZ']\n",
        "return_col = 'log_return' # alternatively use 'ret' to get standard returns"
      ],
      "id": "3653c6e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following we complete the exercises for mandatory assignment 1.\n",
        "\n",
        "**Exercise 1. Compute monthly returns for each of the tickers.**"
      ],
      "id": "143ea5fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inputdf = pd.read_pickle(r'DJ_comp.pkl') # inputdf = yf.download(tickers=tickerlist,period='25y')\n",
        "# transform the dataset\n",
        "df = (inputdf\n",
        "      .get('Adj Close')\n",
        "      .stack()\n",
        "      .reset_index()\n",
        "      .rename(columns={'Date':'date','level_1':'ticker',0:'adj_close'})\n",
        "      .set_index('date')\n",
        "      .groupby('ticker')['adj_close']\n",
        "      .resample('m')\n",
        "      .last()\n",
        "      .reset_index()\n",
        "      .assign(date=lambda x: x['date'].dt.strftime('%Y-%m-%d'))  # Convert date to string\n",
        "      .query(\"date >= '2000-01-01'\")  # Filter for dates >= 1999-04-01\n",
        "      .query(\"date <= '2023-12-31'\")  # Filter for dates >= 1999-04-01\n",
        "      )\n",
        "\n",
        "# remove all tickers where there is no data for each month \n",
        "df = (df\n",
        "  .groupby([\"ticker\"])\n",
        "  .apply(lambda x: x.assign(counts=x[\"adj_close\"].dropna().count()))\n",
        "  .reset_index(drop=True)\n",
        "  .query(\"counts == counts.max()\")\n",
        "  .drop(columns='counts')\n",
        "  .assign(ret=lambda x: x[\"adj_close\"].pct_change())\n",
        "  .assign(log_return = lambda x: np.log(x['adj_close']/x['adj_close'].shift(1)) )\n",
        ")\n",
        "\n",
        "# check that we have 27 tickers\n",
        "no_of_tickers = int(df['ticker'].unique().size)\n",
        "#print(f'The number of tickers in the dataset: { no_of_tickers}')\n",
        "\n",
        "#\n",
        "mu = np.array(df.groupby('ticker')[return_col].mean()).T\n",
        "sigma = np.array(df.pivot(index='date',columns='ticker',values=return_col).cov())"
      ],
      "id": "ffa19eaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We load data for a 25 year period for all constituents of the Dow Jones 30 Index. The dataset is cleaned by removing all consituents that don't have price data for each trading day in the period January 1st 2000 to December 31st 2023. `{python} len(inputdf['ticker'].unique())-len(df['ticker'].unique())` constituents are removed due to no price data. \n",
        "Further, we calculate the monthly return for each ticker in the dataset. Here, we have chosen to use `{python} if return_col == 'log_return': 'log return' else: 'standard return'`\n",
        "\n",
        "**Exercise 2. Which of the 𝑁 individual assets delivered the highest Sharpe ratio?**"
      ],
      "id": "8d39e0be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate Sharpe ratio for each stock\n",
        "sharpe_ratio = (mu - 0) / np.diag(sigma)\n",
        "# Print the Sharpe ratio\n",
        "sr_high = df.groupby('ticker')['ticker'].first().iloc[sharpe_ratio.argmax()]"
      ],
      "id": "8b215f4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the monthly return series calculated earlier, we create a vector of the average monthly returns $\\mu$ for each series and a variance-covariance matrix $\\Sigma$. To calculate the Sharpe-ratio, we use the formula: $Sharpe=\\frac{return-r_f}{standarddeviation}$. The stock with the highest Sharpe ratio is `{python} sr_high` with a ration of `{python} sharpe_ratio.max().round(2)`.\n"
      ],
      "id": "00743942"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def calc_return_std(weights, mu, sigma_matrix, factor):\n",
        "  \"\"\"\n",
        "  Calculate the expected return and standard deviation of a portfolio.\n",
        "\n",
        "  Parameters:\n",
        "  weights (numpy.ndarray): The weights of the assets in the portfolio.\n",
        "  mu (numpy.ndarray): The expected returns of the assets.\n",
        "  sigma_matrix (numpy.ndarray): The covariance matrix of the assets.\n",
        "  factor (float): A scaling factor.\n",
        "\n",
        "  Returns:\n",
        "  tuple: A tuple containing the expected return and standard deviation of the portfolio.\n",
        "  \"\"\"\n",
        "  return_vec = mu.T @ weights * factor \n",
        "  vol = np.sqrt(weights.T @ sigma_matrix @ weights) * np.sqrt(factor)\n",
        "  return return_vec, vol"
      ],
      "id": "e0439ab5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exercise 3. Perform each of the following steps:**\n",
        "First of we create a function compute_efficient_frontier which return an object with the inputs that consists of a vector of the estimated expected return, the estimated variance-covariance matrix and a factor that is used to annualised the return, minimum variance portfolio, efficient portfolio that delivers two times the expected return of the minimum variance portfolio and lastly the efficient frontier. \n",
        "*How are the different things calculated*\n",
        "***Compute the minimum variance portfolio weight**\n",
        "To compute the minimum variance portfolio we perform\n"
      ],
      "id": "6792e02b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compute_efficient_frontier(mu_est: np.array, sigma_est: np.array, yearly_factor: int=1) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    The function performs each of the following steps:\n",
        "    1. Compute the minimum variance portfolio weight mvp_weights for the input Sigma_est. \n",
        "        The function can handle positive definite variance-covariance matrices of arbitrary dimensions N x N.\n",
        "    2. Compute the eﬀicient portfolio weights efp_weights for the inputs Sigma_est and mu_est \n",
        "      that delivers two times the expected return of the minimum variance portfolio weight.\n",
        "    3. Make use of the two-mutual fund theorem to characterize a range of portfolio weights on the eﬀicient frontier: \n",
        "      Specifically, compute the weights of a sequence of portfolios which are combinations of the minimum variance portfolio weight\n",
        "        and the eﬀicient portfolio, c_weights = c * mvp_weights  + (1 - c) * efp_weights where c ∈ {-0.1, ... , 1.2}\n",
        "    \n",
        "      Args: \n",
        "        mu_est (np.array): N x 1 return matrix\n",
        "        sigma_est (np.array): N x N variance-covariance matrix\n",
        "      Returns: \n",
        "        df: with column c which is the weight of the minimum variance portfolio and N corresponding columns with the weights \n",
        "          of each asset\n",
        "    \"\"\"\n",
        "    class results: pass\n",
        "    results.inputs = {}\n",
        "    results.inputs['mu'] = mu_est\n",
        "    results.inputs['sigma'] = sigma_est\n",
        "    results.inputs['yearly_factor'] = yearly_factor\n",
        "\n",
        "    N = mu_est.shape[0]\n",
        "    if sigma_est.shape[0] != N: \n",
        "        raise ValueError('The size length of vector mu_est should be the same as for sigma_est')\n",
        "    iota = np.ones(N)\n",
        "    sigma_inv = np.linalg.inv(sigma_est) \n",
        "\n",
        "    #----- minimum variance portfolio\n",
        "    mvp_weights = sigma_inv @ iota\n",
        "    mvp_weights = mvp_weights/mvp_weights.sum()\n",
        "    mvp_return,mvp_volatility =  calc_return_std(mvp_weights,mu,sigma_est,yearly_factor)\n",
        "    print(f'Return of the minimum variance portfolio is: {mvp_return:.2f} and its volatility is {mvp_volatility:.2f}')\n",
        "    results.mvp_weights = mvp_weights  # store minimum variance portfolio weights in object\n",
        "\n",
        "    #----- efficient frontier portfolio\n",
        "    mu_bar = mvp_return*2\n",
        "    C = iota.T @ sigma_inv @ iota\n",
        "    D = iota.T @ sigma_inv @ mu_est\n",
        "    E = mu_est.T @ sigma_inv @ mu_est\n",
        "    lambda_tilde = 2 * (mu_bar - D/C) / (E-D**2/C)\n",
        "    efp_weights = mvp_weights + lambda_tilde/2 * (sigma_inv@mu_est - D* mvp_weights ) \n",
        "    efp_return,efp_vol =  calc_return_std(efp_weights,mu,sigma_est,yearly_factor)\n",
        "    print(f'Return of the efficient frontier portfolio is: {efp_return:.2f} and its volatility is {efp_vol:.2f}')\n",
        "    results.efp_weights = efp_weights # store efficient frontier portfolio weights in object\n",
        "\n",
        "    #----- mutual fund theorem\n",
        "    a = np.linspace(-0.2, 1.2, 121)\n",
        "    res = pd.DataFrame(columns=[\"mu\", \"sd\"], index=a).astype(float)\n",
        "    for i in a:\n",
        "        w = i*mvp_weights+(1-i)*efp_weights\n",
        "        for j in range(len(w)):\n",
        "          res.loc[i, f\"w_{j+1}\"] = w[j]  # Assign each element of w to a named column\n",
        "        res.loc[i, \"mu\"] = (w.T @ mu)*yearly_factor\n",
        "        res.loc[i, \"sd\"] = np.sqrt(w.T @ sigma @ w)*np.sqrt(yearly_factor)\n",
        "    \n",
        "    results.res = res   # store dataframe in object \n",
        "\n",
        "    return results"
      ],
      "id": "af9d3440",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cef = compute_efficient_frontier(mu_est=mu,sigma_est=sigma,yearly_factor=12)\n",
        "\n",
        "efpRet, efpVol = calc_return_std(weights=cef.efp_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])\n",
        "efpSR = efpRet/efpVol\n",
        "\n",
        "mvpRet, mvpVol = calc_return_std(weights=cef.mvp_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])\n",
        "mvpSR = mvpRet/mvpVol"
      ],
      "id": "86111042",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The minimum variance portfolio has a expected return of `{python} (mvpRet*100).round(2)` and a volatility of `{python} (mvpVol*100).round(2)`. While the volatility of the efficient portfolio that delivers two times the expected return of the minimum variance is `{python} (efpVol*100).round(2)`. We notice that the Sharpe ratio `{python} if mvpSR > efpSR: 'decreases' else: 'increases'` from `{python} mvpSR` to `{python} efpSR`. \n"
      ],
      "id": "8edd3c96"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#---- tangency portfolio\n",
        "# ¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿\n",
        "#       connsider if there is a better way\n",
        "# ????????????????????????????????????????????????\n",
        "d = np.vstack((cef.inputs['sigma'],np.ones(27)))\n",
        "c = np.append(cef.inputs['mu'],0)\n",
        "e = np.hstack((d,c.reshape(c.shape[0],1)))\n",
        "q = np.append(np.zeros(cef.inputs['mu'].shape[0]),1)\n",
        "tan_weights = np.linalg.inv(e) @ q\n",
        "tan_weights = tan_weights[:-1]\n",
        "tanRet, tanVol = calc_return_std(weights=tan_weights,mu=cef.inputs['mu'],sigma_matrix=cef.inputs['sigma'],factor=cef.inputs['yearly_factor'])\n",
        "\n",
        "# sharpe-ratio\n",
        "sharpeRatio = tanRet/tanVol\n",
        "\n",
        "vol = np.linspace(0,tanVol,101)\n",
        "x = np.linspace(0,1,101)\n",
        "ret = np.nan + np.zeros(vol.shape[0])\n",
        "for i, v in enumerate(x):\n",
        "   ret[i] = tanRet * v\n",
        "tanLine = pd.DataFrame((vol,ret),index=['vol','ret']).T\n",
        "\n",
        "res_figure = (\n",
        "  ggplot(cef.res, aes(x=\"sd\", y=\"mu\")) +\n",
        "  geom_point() + \n",
        "  geom_line(tanLine, aes(x='vol',y='ret'))+\n",
        "  geom_point(\n",
        "    pd.DataFrame({\"mu\": [mvpRet, efpRet,tanRet],\"sd\":[mvpVol, efpVol,tanVol]}),\n",
        "    size=4, \n",
        "    color='darkblue',\n",
        "    ) +\n",
        "  geom_point(\n",
        "    pd.DataFrame({\"mu\": cef.inputs['mu']*12,\n",
        "                  \"sd\": np.sqrt(np.diag(cef.inputs['sigma'])) * np.sqrt(12)\n",
        "                  })\n",
        "  ) +\n",
        "  labs(x=\"Annualized standard deviation\",\n",
        "       y=\"Annualized expected return\",\n",
        "       title=\"Efficient frontier for DOW index constituents\") +\n",
        "  scale_x_continuous(labels=percent_format()) +\n",
        "  scale_y_continuous(labels=percent_format())\n",
        ")"
      ],
      "id": "1af92853",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "res_figure"
      ],
      "id": "47b7ac21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exercise 4. Efficient tangency:**\n",
        "*What are the eﬀicient tangency portfolio weights 𝜔tgc under the assumption that the risk- free rate is zero based on the true parameters 𝜇 and Σ? Do the tangency portfolio weights seem like a well-balanced portfolio? What are the potential issues when implementing this portfolio in reality? What is the maximum attainable Sharpe ratio assuming the risk-free rate is zero? Should the Sharpe ratio of 𝜔tgc be higher or lower than the Sharpe ratio of the individual assets?*\n",
        "\n",
        "\n",
        "\n",
        "**Exercise 4. Explain the code:**"
      ],
      "id": "15918525"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}